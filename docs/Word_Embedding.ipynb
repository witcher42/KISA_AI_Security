{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SugBhi3GCYJ-",
        "colab_type": "text",
        "colab": {}
      },
      "source": [
        "# 단어 토큰화, Embedding, LSTM layer를 활용한 뉴스 데이터 sarcasm 판단\n", 
        "https://teddylee777.github.io/tensorflow/news-sarcasm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKa-F2LbqaHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fodCFZ9vB5J2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3afe9783-5695-4f8f-ac4c-ce8923ab24b1"
      },
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "urllib.request.urlretrieve(url, 'sarcasm.json')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sarcasm.json', <http.client.HTTPMessage at 0x7fbee4c5cba8>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z3YpwZpB-ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('sarcasm.json', 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvJNGtmvCBHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "482e3ead-4853-479f-d71e-06a270f5554e"
      },
      "source": [
        "data[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
              "  'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "  'is_sarcastic': 0},\n",
              " {'article_link': 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365',\n",
              "  'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              "  'is_sarcastic': 0},\n",
              " {'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697',\n",
              "  'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              "  'is_sarcastic': 1},\n",
              " {'article_link': 'https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302',\n",
              "  'headline': 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
              "  'is_sarcastic': 1},\n",
              " {'article_link': 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb',\n",
              "  'headline': 'j.k. rowling wishes snape happy birthday in the most magical way',\n",
              "  'is_sarcastic': 0}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVPRx02FCEV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a54b8f0-901b-452f-e80c-13350cd89486"
      },
      "source": [
        "labels = []\n",
        "sentences = []\n",
        "for d in data:\n",
        "    sentences.append(d['headline'])\n",
        "    labels.append(d['is_sarcastic'])\n",
        "\n",
        "train_ratio = 0.8\n",
        "train_size = int(len(data) * train_ratio)\n",
        "train_size, len(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21367, 26709)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z2UKgKQCwrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences = sentences[:train_size]\n",
        "valid_sentences = sentences[train_size:]\n",
        "train_labels = labels[:train_size]\n",
        "valid_labels = labels[train_size:]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKF2cpxXC2Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocab_size는 Token화 진행시 최대 빈도숫자가 높은 1000개의 단어만을 활용하겠다는 의미  \n",
        "vocab_size = 1000\n",
        "token = Tokenizer(vocab_size, oov_token='<OOV>')  \n",
        "token.fit_on_texts(sentences)\n",
        "word_index = token.word_index"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upIKsOwcDL7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "9b224616-d7d2-42b8-a279-da7be3b314d9"
      },
      "source": [
        "# Tokenizer로 sentences를 numerical value로 변환\n",
        "train_sequences = token.texts_to_sequences(train_sentences)\n",
        "valid_sequences = token.texts_to_sequences(valid_sentences)\n",
        "train_sentences[:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              " \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
              " \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
              " 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas',\n",
              " 'j.k. rowling wishes snape happy birthday in the most magical way']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cES0-740EJzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "d2f850fc-3c2a-47d9-8b94-a9f4dce6d44d"
      },
      "source": [
        "train_sequences[:5]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[308, 1, 679, 1, 1, 48, 382, 1, 1, 6, 1, 1],\n",
              " [4, 1, 1, 1, 22, 2, 166, 1, 416, 1, 6, 258, 9, 1],\n",
              " [145, 838, 2, 907, 1, 1, 582, 1, 221, 143, 39, 46, 2, 1],\n",
              " [1, 36, 224, 400, 2, 1, 29, 319, 22, 10, 1, 1, 1, 968],\n",
              " [767, 719, 1, 908, 1, 623, 594, 5, 4, 95, 1, 92]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTVHn8J8EZBF",
        "colab_type": "text"
      },
      "source": [
        "# 6. 문장의 길이 맞추기 (pad_sequences)\n",
        "학습을 위해서는 input의 길이가 동일 해야    \n",
        "지금의 sequences는 길이가 들쭉날쭉    \n",
        "pad_sequences를 통해 길이가 긴 문장을 자르거나, 길이가 짧은 문장은 padding     "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6KsD1SVEOwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_padded = pad_sequences(train_sequences, truncating='post', padding='post', maxlen=120)\n",
        "valid_padded = pad_sequences(valid_sequences, truncating='post', padding='post', maxlen=120)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DVfA8Y3EmtW",
        "colab_type": "text"
      },
      "source": [
        "#7. label을 np.array로 변환\n",
        "list 타입은 허용하지 않기 때문에, labels를 np.array로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_RSHCjHEiZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00a60556-53af-44f1-c239-40624b45a529"
      },
      "source": [
        "train_labels = np.asarray(train_labels)\n",
        "valid_labels = np.asarray(valid_labels)\n",
        "train_labels, valid_labels"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 1, ..., 0, 1, 1]), array([1, 1, 1, ..., 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JiRAEZEE6NA",
        "colab_type": "text"
      },
      "source": [
        "#8. 모델링 (Modeling)\n",
        "vocab_size = 1000이므로 단어들은 1000차원 공간안에 정의되어 있다고 말할 수 있다          \n",
        "이를 16차원으로 내려 Data Sparsity를 해결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlSyGeocEsMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "a98b3408-5917-4e63-a115-2673a05f106e"
      },
      "source": [
        "model = Sequential([Embedding(vocab_size, embedding_dim=16, input_length=_maxlen), Bidirectional(LSTM(32)),\n",
        "        Dense(24, activation='relu'), Dense(1, activation='sigmoid')])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 120, 16)           16000     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                12544     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 30,129\n",
            "Trainable params: 30,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJiYpuOJFBq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e04e4015-f500-4b71-b516-dfc7390bc7d0"
      },
      "source": [
        "checkpoint_path = 'best_performed_model.ckpt'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
        "                                                save_weights_only=True, \n",
        "                                                save_best_only=True, \n",
        "                                                monitor='val_loss',\n",
        "                                                verbose=1)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(train_padded, train_labels, \n",
        "                    validation_data=(valid_padded, valid_labels),\n",
        "                    callbacks=[checkpoint],\n",
        "                    epochs=20, \n",
        "                    verbose=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.38456, saving model to best_performed_model.ckpt\n",
            "668/668 - 42s - loss: 0.4470 - accuracy: 0.7767 - val_loss: 0.3846 - val_accuracy: 0.8186\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.38456 to 0.37276, saving model to best_performed_model.ckpt\n",
            "668/668 - 41s - loss: 0.3497 - accuracy: 0.8390 - val_loss: 0.3728 - val_accuracy: 0.8289\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.37276 to 0.36713, saving model to best_performed_model.ckpt\n",
            "668/668 - 42s - loss: 0.3268 - accuracy: 0.8517 - val_loss: 0.3671 - val_accuracy: 0.8282\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.36713 to 0.36418, saving model to best_performed_model.ckpt\n",
            "668/668 - 41s - loss: 0.3109 - accuracy: 0.8602 - val_loss: 0.3642 - val_accuracy: 0.8340\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.36418\n",
            "668/668 - 42s - loss: 0.3023 - accuracy: 0.8653 - val_loss: 0.3815 - val_accuracy: 0.8265\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2937 - accuracy: 0.8694 - val_loss: 0.3745 - val_accuracy: 0.8338\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2844 - accuracy: 0.8757 - val_loss: 0.3698 - val_accuracy: 0.8377\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2780 - accuracy: 0.8766 - val_loss: 0.3817 - val_accuracy: 0.8298\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2732 - accuracy: 0.8786 - val_loss: 0.3854 - val_accuracy: 0.8295\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.36418\n",
            "668/668 - 42s - loss: 0.2669 - accuracy: 0.8843 - val_loss: 0.3902 - val_accuracy: 0.8362\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2612 - accuracy: 0.8865 - val_loss: 0.4287 - val_accuracy: 0.8225\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2565 - accuracy: 0.8889 - val_loss: 0.4029 - val_accuracy: 0.8298\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2514 - accuracy: 0.8920 - val_loss: 0.4047 - val_accuracy: 0.8325\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.36418\n",
            "668/668 - 42s - loss: 0.2432 - accuracy: 0.8933 - val_loss: 0.4147 - val_accuracy: 0.8313\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2360 - accuracy: 0.8994 - val_loss: 0.4371 - val_accuracy: 0.8291\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2282 - accuracy: 0.9017 - val_loss: 0.4363 - val_accuracy: 0.8263\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.36418\n",
            "668/668 - 42s - loss: 0.2222 - accuracy: 0.9046 - val_loss: 0.4533 - val_accuracy: 0.8283\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.36418\n",
            "668/668 - 42s - loss: 0.2139 - accuracy: 0.9093 - val_loss: 0.4701 - val_accuracy: 0.8313\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.2057 - accuracy: 0.9129 - val_loss: 0.4774 - val_accuracy: 0.8252\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.36418\n",
            "668/668 - 41s - loss: 0.1980 - accuracy: 0.9167 - val_loss: 0.5312 - val_accuracy: 0.8287\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
