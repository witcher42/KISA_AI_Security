{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "ML_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-0LzD7y1KEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 혼자하는 머신러닝 학습 2020.08.15\n",
        "# 단톡방에도 공유를 했는데, '문자를 인코딩하고 딕셔너리의 0과 1로 매핑하기'에 대한 추가학습이 필요!"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "elABF_Ael5qP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "451e8ff7-c26f-48dc-e1f4-401d5290e572"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "# 신용카드 사기 검출\n",
        "card_df = pd.read_csv('./creditcard.csv')\n",
        "card_df.head()\n",
        "# Time: Elapsed between transactions, drop-out\n",
        "# Amount: Transaction\n",
        "# Class: 0-normal, 1-abnormal"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRrRKltbl5qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Time: drop-out\n",
        "def preprocessed_df_origin(df=None):\n",
        "    df_copy = df.copy()\n",
        "    df_copy.drop('Time', axis=1, inplace=True)\n",
        "    return df_copy\n",
        "\n",
        "def train_test_df_origin(df=None):\n",
        "    df_copy = preprocessed_df_origin(df)\n",
        "    # target == Class\n",
        "    X_features = df_copy.iloc[:, :-1]\n",
        "    Y_target = df_copy.iloc[:, -1]\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y_target, test_size=0.3, random_state=1, stratify=Y_target)\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnthUmFvl5qZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "# Evaluation Function\n",
        "def ML_score(Y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix(Y_test, pred)\n",
        "    accuracy = accuracy_score(Y_test, pred)\n",
        "    precision = precision_score(Y_test, pred)\n",
        "    recall = recall_score(Y_test, pred)\n",
        "    f1 = f1_score(Y_test, pred)\n",
        "    roc_auc = roc_auc_score(Y_test, pred_proba)\n",
        "    print('Confusion Matrix\\n', confusion)\n",
        "    print('Acc = {0:.4f}, Prec = {1:.4f}, Recall = {2:.4f}, F1 = {3:.4f}, AUC = {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMedNF2fl5qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "def ML_tester(model, in_train=None, in_test=None, out_train=None, out_test=None):\n",
        "    model.fit(in_train, out_train)\n",
        "    pred = model.predict(in_test)\n",
        "    pred_proba = model.predict_proba(in_test)[:, 1]\n",
        "    # 모델평가\n",
        "    ML_score(out_test, pred, pred_proba)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMNXSdY53PXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "e407df65-a025-4027-cc51-b274fd905fc0"
      },
      "source": [
        "card_df['Amount'].value_counts()\n",
        "# 이상치 확인"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.00       13688\n",
              "1.98        6044\n",
              "0.89        4872\n",
              "9.99        4747\n",
              "15.00       3280\n",
              "           ...  \n",
              "192.63         1\n",
              "218.84         1\n",
              "195.52         1\n",
              "793.50         1\n",
              "1080.06        1\n",
              "Name: Amount, Length: 32767, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPZyqDn_Wit",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "e77ef6b4-7f0d-43c9-ab2b-c3167f6f92a6"
      },
      "source": [
        "corr = card_df.corr(method = 'pearson').iloc[:,-1]\n",
        "# 피어슨 상관관계 분석, 1에 가까울수록 강한 상관관계\n",
        "corr"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time     -0.012323\n",
              "V1       -0.101347\n",
              "V2        0.091289\n",
              "V3       -0.192961\n",
              "V4        0.133447\n",
              "V5       -0.094974\n",
              "V6       -0.043643\n",
              "V7       -0.187257\n",
              "V8        0.019875\n",
              "V9       -0.097733\n",
              "V10      -0.216883\n",
              "V11       0.154876\n",
              "V12      -0.260593\n",
              "V13      -0.004570\n",
              "V14      -0.302544\n",
              "V15      -0.004223\n",
              "V16      -0.196539\n",
              "V17      -0.326481\n",
              "V18      -0.111485\n",
              "V19       0.034783\n",
              "V20       0.020090\n",
              "V21       0.040413\n",
              "V22       0.000805\n",
              "V23      -0.002685\n",
              "V24      -0.007221\n",
              "V25       0.003308\n",
              "V26       0.004455\n",
              "V27       0.017580\n",
              "V28       0.009536\n",
              "Amount    0.005632\n",
              "Class     1.000000\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mHvDt7ol5qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dropout_df(df=None, column=None, weight=1.5):\n",
        "    # column == Amount2\n",
        "    fraud = df[df['Class']==1][column]\n",
        "    quarter_25 = np.percentile(fraud.values, 25)\n",
        "    quarter_75 = np.percentile(fraud.values, 75) \n",
        "    IQR_BOX = (quarter_75 - quarter_25) * weight\n",
        "    min = quarter_25 - IQR_BOX\n",
        "    max = quarter_75 + IQR_BOX\n",
        "    dropout = fraud[(fraud < min) | (fraud > max)].index\n",
        "    # return DataFrame Index\n",
        "    return dropout"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmUvmHRgl5qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이상치 제거\n",
        "def preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "    amount_scaler = np.log1p(df_copy['Amount'])\n",
        "    df_copy.insert(0, 'newAmount', amount_scaler)\n",
        "    df_copy.drop(['Time','Amount'], axis=1, inplace=True)\n",
        "    index = dropout_df(df_copy, 'V17', 1.5)\n",
        "    df_copy.drop(index, axis=0, inplace=True)\n",
        "    return df_copy\n",
        "\n",
        "def train_test_df(df=None):\n",
        "    df_copy = preprocessed_df(df)\n",
        "    # target == Class\n",
        "    X_features = df_copy.iloc[:, :-1]\n",
        "    Y_target = df_copy.iloc[:, -1]\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y_target, test_size=0.3, random_state=1, stratify=Y_target)\n",
        "    return X_train, X_test, Y_train, Y_test"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcjkUKRS6Wbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "4bb85bc9-7fc6-4037-cf3a-993afb03c665"
      },
      "source": [
        "# 분류 모델인 로지스틱 회귀 로드!\n",
        "# 로지스틱 회귀는 텍스트 분류에서 뛰어난 성능!\n",
        "classifier = LogisticRegression()\n",
        "print(\"초기 모델 평가\")\n",
        "X_train, X_test, Y_train, Y_test = train_test_df_origin(card_df)\n",
        "ML_tester(classifier, X_train, X_test, Y_train, Y_test)\n",
        "print(\"\\n이상치 제거 후 모델 평가\")\n",
        "X_train, X_test, Y_train, Y_test = train_test_df(card_df)\n",
        "ML_tester(classifier, X_train, X_test, Y_train, Y_test)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "초기 모델 평가\n",
            "Confusion Matrix\n",
            " [[85280    15]\n",
            " [   48   100]]\n",
            "Acc = 0.9993, Prec = 0.8696, Recall = 0.6757, F1 = 0.7605, AUC = 0.9634\n",
            "\n",
            "이상치 제거 후 모델 평가\n",
            "Confusion Matrix\n",
            " [[85284    11]\n",
            " [   45   103]]\n",
            "Acc = 0.9993, Prec = 0.9035, Recall = 0.6959, F1 = 0.7863, AUC = 0.9790\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}