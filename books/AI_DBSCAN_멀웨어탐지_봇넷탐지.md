# Word2Vec과 가속화 계층적 밀집도 기반 클러스터링을 활용한 효율적 봇넷 탐지 기법  
## - 멀웨어 탐지 디비스캔 클러스터링   
이태일 ‖ 한국교통대학교  
김관현 ‖ 한국교통대학교  
이지현 ‖ 한국교통대학교   
이수철 ‖ 한국교통대학교  
💼📜  
  
## DDoS 대응방안
- DDoS공격은 현존 백신을 이용하여 탐지하기가 매우 어렵다  
- 왜냐하면 통상의 악성코드 탐지 기법은 시그니처에 기반을 두는데,  
  - DDoS 공격을 수행하는 악성코드 내에서 특정 시그니처를 포함하지 않는 경우도 다반사이며  
  - 특정 시그니처가 존재한다손 치더라도 공격자는 이를 계속 변화, 진화시킬 것이다.  
  - 통상적으로 특정 시그니처를 밝혀내는 데에는 악성코드 채증, 채증된 악성코드의 심층 분석, 분석을 통해  
  - 최종적으로 특정된 시그니처를 악성코드 탐지 소프트웨어나 백신에 업데이트하여야 하므로 방대한 시간과 비용이 소모    
- 따라서 신속하게 DDoS공격을 무력화 시키는 방법은 실질적으로 존재할 수 없다고 하겠다.  
- 시그니처 기반 방법으로 제로데이 DDoS공격에 대한 신속한 탐지는 거의 불가능한 문제가 된다.

- DDoS 공격 시도, 패킷, 페이로드 가로채기및 대상 노드 크래킹과 같은 악성 공격에 대해 효과적으로 대응하기 위하여  
- 통상적인 멀웨어 바이너리에서 시그니처를 분석, 추출하는 방식과 달리 트래픽의 송수신지등과 네트워크 정보를 기반으로 시그니처를 생성하는 방법을 제안  
  - 시그니처 생성에 있어 5-tuple 중 송신지 포트를 제외한 4-tuple(송신지 IP 주소, 수신지 IP 주소, 프로토콜, 수신지 포트번호)로  
  - 워드 임베딩(word embeddi ng)을 구성하고 이를 자연어 학습 모델인 Word2Vec의 Skip-gram 알고리즘을 활용한 봇넷 탐지 방법을 제안함  
  
## Word2Vec과 이상트래픽 탐지
- 인공지능 등 기계학습 기반 멀웨어 분석 및 분류기술은 전처리 단계를 거치게 된다.  
- 통상적으로 기계학습 연구 분야에서는 이 과정을 특징 공학(feature engineering)이라 한다  
- 신경망 기반 클러스터링 알고리즘인 SOM (Self Organizing Maps)을 활용하여 다양한 시나리오에서 효과적으로 멀웨어를 탐지 할 수 있음이 입증되었다
- 4개의 특징(송신지 IP 주소, 수신지 IP주소, 프로토콜, 수신지 포트번호)에 대하여 Skip-gram기법을 활용하여 각 단어를 벡터화 하였다.  
  - 각 단어 벡터 사이의 코사인 유사도를 측정하여 비정상 트래픽을 탐지하였다. 
  - 분자의 지수의 증가는 타깃 단어에 해당하는 벡터와 주변 단어에 해당하는 벡터의 내적 값의 증가를 의미  
  - 벡터 내적은 코사인이므로 내적 값의 증가는 단어 벡터 간 유사도의 증가를 의미    
  - 반대로 분모의 감소는 윈도우 크기 내에 등장하지 않는단어들은 중심 단어와의 유사도를 감소시킨다 
- 학습 과정에서 포트 번호가 동음이의어로 사용될 가능성이 많으며, 이로 인해 발생하는 탐지 성능 저하문제를 해결하기 위하여 전처리 과정을 변경하였다.  
- 비정상 트래픽을 더욱 명확하게 분류하기 위한 기법으로 밀도 기반 클러스터링(DBScan: Density Based Spatial Clustering of Application with noise)기법을 도입  
- 송신지 포트번호는 송신자가 직접 바인딩하지 않을 경우 랜덤하게 선택된 포트번호로 연결을 수립하므로 특징을 추출할 수 없고  
- 대부분의 호스트는 소켓의 송신지 포트번호를 특정포트와 연관시키지 않아 불필요한 계산이 증가하는 문제점을 야기함  
  
- 학습을 위해 입력된 단어는 원 핫 벡터(one-hot vector)의 형태로 입력되며, 학습 후 임베딩 된 단어는 벡터 값을 갖는다   
- 입력층과 출력층은 같은 크기의 차원을 가지며, 은닉층의 뉴런은 입력층보다 저차원이어야 한다.  
- 은닉층에 처음에 설정된 임의의 초기 가중치 값들은 학습이 진행되면서 loss가 최소가 되는 최적의 가중치를 갖도록 학습된다.  
- 결론적으로, Skip-gram 인공신경망의 은닉층에가중치 행렬 W, W′을 구하는 것이 궁극적인 목표가 된다.  
  
- 은닉층에는 각 단어의 임베딩 최종 결과가 저장되기 때문에 은닉층이 곧 Word2Vec이다  
- 모든 훈련 과정들에서, 문장(context)에 있는 단어에 포함된 모든 단어에 대한 확률을 계산하고 정규화해야 한다. 따라서 계산 비용이 매우 크다.   
- 계산 비용을 최소화하기 위하여 본 연구에서는 비용함수로 NCE (Noise Contrastive estimation)를 사용하였다  
  - NCE는 CBOW 와 Skip-gram 모델에 사용하는 비용 계산 알고리즘  
  
### 학습절차  
- Word2Vec은 자연어를 학습하기 위하여 만든 모델
  - 비슷한 맥락에 등장하는 단어들은 유사한 의미를 지니는 경향이 있다는 이론인 Distributional Hypnosis에 기반  
  - 윈도우 크기에 따라 비슷한 구간에서 출현하는 자연어끼리의 유사도를 학습하는 모델이므로 한 개의 네트워크 플로우를 한 개의 자연어 문장으로 취급함  
  - 하지만 윈도우 크기에 종속되어 단어끼리의 학습을 진행하면 연관성이 적은 특징들끼리의 단어 쌍을구성하는 것은 결과적으로 정확도를 저해함  
    - 입력 특징을 기준으로 통신상에 연관이 깊은 특징끼리만 학습하게 하였다.  
  - 단어임베딩의 대표적인 모델인 Word2Vec Skip-gram 방법론에 따라 학습 모델 생성을 진행   
  - 타깃 단어를 기반으로 문장(네트워크 플로우)을 학습  
    - ① 송신지 IP주소가 프로토콜 또는 수신지 IP 주소와 단어 쌍을 이룰 수 있다.
    - ② 수신지 IP주소는 목적지 IP주소와 쌍을 이룰 수 있다.       
    - ③ 수신지 포트번호는 프로토콜 또는 송신지 IP 주소와쌍을 이룰 수 있다.
    - ④ 프로토콜은 송신지 IP주소 또는 수신지 포트번호와쌍을 이룰 수 있다.
 
## DBScan 클러스터링  
- 비정상 트래픽을 더욱 명확하게 분류하기 위한 기법 군집의 개수를 따로 정하지 않아도 비선형 경계의 군집을 구할 수 있다  
  - Malware (멀웨어)탐지에 있어서 DBScan클러스터링이 활용된 사례가 다수 있다.   
  - 그러나 DBScan 알고리즘은 밀도 위주로 계산이 이루어지기 때문에 높은 계산량을 요구    
  - 실제의 활용에 있어서 DBScan 알고리즘을 적용하고자 한다면 수천~수억건의 플로우 데이터를 실시간으로 처리해야 한다. 
    - 따라서 DBScan방법을 실시간으로 실제의 봇넷 탐지에 적용하기에는 한계가 있다    
  - 전체 데이터를 랜덤하게 분할하여 클러스터링을 수행하고 그 결과값을 누적시키는 분할정복 등의 기법으로 계산수행시간을 완화할 수 있다  
